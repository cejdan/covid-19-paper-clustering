{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_csv_path = os.path.join(os.path.abspath(os.path.curdir), \"docs\\\\CORD-19-research-challenge\\\\metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51078 entries, 0 to 51077\n",
      "Data columns (total 18 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   cord_uid                     51078 non-null  object \n",
      " 1   sha                          38022 non-null  object \n",
      " 2   source_x                     51078 non-null  object \n",
      " 3   title                        50920 non-null  object \n",
      " 4   doi                          47741 non-null  object \n",
      " 5   pmcid                        41082 non-null  object \n",
      " 6   pubmed_id                    37861 non-null  float64\n",
      " 7   license                      51078 non-null  object \n",
      " 8   abstract                     42352 non-null  object \n",
      " 9   publish_time                 51070 non-null  object \n",
      " 10  authors                      48891 non-null  object \n",
      " 11  journal                      46368 non-null  object \n",
      " 12  Microsoft Academic Paper ID  964 non-null    float64\n",
      " 13  WHO #Covidence               1768 non-null   object \n",
      " 14  has_pdf_parse                51078 non-null  bool   \n",
      " 15  has_pmc_xml_parse            51078 non-null  bool   \n",
      " 16  full_text_file               42511 non-null  object \n",
      " 17  url                          50776 non-null  object \n",
      "dtypes: bool(2), float64(2), object(14)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "metaCSV = pd.read_csv(metadata_csv_path)\n",
    "metaCSV.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaCSV = metaCSV[['cord_uid', 'sha', 'pmcid', 'title', 'abstract', 'authors', 'journal']]\n",
    "#metaCSV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaCSV.dropna(inplace=True, subset = {'title', 'abstract', 'sha'})\n",
    "\n",
    "#metaCSV['sha']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Nic\\\\PycharmProjects\\\\cs5293sp20-project2\\\\docs\\\\CORD-19-research-challenge\\\\comm_use_subset\\\\comm_use_subset\\\\pdf_json\\\\5b68a553a7cbbea13472721cd1ad617d42b40c26.json'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = metaCSV.iloc[3,1] + \".json\"\n",
    "filepath = \"docs\\\\CORD-19-research-challenge\\\\comm_use_subset\\\\comm_use_subset\\\\pdf_json\\\\\" + filename\n",
    "os.path.abspath(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(os.path.abspath(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " ...]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This block will create a boolean filter to remove all the rows that are not in the comm_use_subset\n",
    "\n",
    "i = 0\n",
    "in_subset = []\n",
    "for items in metaCSV['sha']:\n",
    "    filename = metaCSV.iloc[i,1] + \".json\"\n",
    "    filepath = \"docs\\\\CORD-19-research-challenge\\\\comm_use_subset\\\\comm_use_subset\\\\pdf_json\\\\\" + filename\n",
    "    os.path.abspath(filepath)\n",
    "    in_subset.append(os.path.exists(os.path.abspath(filepath)))\n",
    "    i = i + 1\n",
    "pd.Series(in_subset)\n",
    "in_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8419 entries, 7 to 51065\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   cord_uid  8419 non-null   object\n",
      " 1   sha       8419 non-null   object\n",
      " 2   pmcid     8404 non-null   object\n",
      " 3   title     8419 non-null   object\n",
      " 4   abstract  8419 non-null   object\n",
      " 5   authors   8409 non-null   object\n",
      " 6   journal   8351 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 526.2+ KB\n"
     ]
    }
   ],
   "source": [
    "meta_CSV = metaCSV[in_subset]\n",
    "meta_CSV.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " ...]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "in_comm_use = []\n",
    "in_noncomm_use = []\n",
    "in_custom_license = []\n",
    "in_biorxiv_medrxiv = []\n",
    "\n",
    "in_any_subset = []\n",
    "\n",
    "for items in metaCSV['sha']:\n",
    "    filename = metaCSV.iloc[i,1] + \".json\"\n",
    "    filepath1 = \"docs\\\\CORD-19-research-challenge\\\\comm_use_subset\\\\comm_use_subset\\\\pdf_json\\\\\" + filename\n",
    "    filepath2 = \"docs\\\\CORD-19-research-challenge\\\\noncomm_use_subset\\\\noncomm_use_subset\\\\pdf_json\\\\\" + filename\n",
    "    filepath3 = \"docs\\\\CORD-19-research-challenge\\\\custom_license\\\\custom_license\\\\pdf_json\\\\\" + filename\n",
    "    filepath4 = \"docs\\\\CORD-19-research-challenge\\\\biorxiv_medrxiv\\\\biorxiv_medrxiv\\\\pdf_json\\\\\" + filename\n",
    "\n",
    "    in_comm_use.append(os.path.exists(os.path.abspath(filepath1)))\n",
    "    in_noncomm_use.append(os.path.exists(os.path.abspath(filepath2)))\n",
    "    in_custom_license.append(os.path.exists(os.path.abspath(filepath3)))\n",
    "    in_biorxiv_medrxiv.append(os.path.exists(os.path.abspath(filepath4)))\n",
    "    \n",
    "    \n",
    "    if in_comm_use[i] == True or in_noncomm_use[i] == True or in_custom_license[i] == True or in_biorxiv_medrxiv[i] == True:\n",
    "        in_any_subset.append(True)\n",
    "    else:\n",
    "        in_any_subset.append(False)\n",
    "    i = i + 1\n",
    "pd.Series(in_any_subset)\n",
    "in_any_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31646 entries, 0 to 51076\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   cord_uid  31646 non-null  object\n",
      " 1   sha       31646 non-null  object\n",
      " 2   pmcid     26925 non-null  object\n",
      " 3   title     31646 non-null  object\n",
      " 4   abstract  31646 non-null  object\n",
      " 5   authors   31487 non-null  object\n",
      " 6   journal   29928 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "meta_CSV = metaCSV[in_any_subset]\n",
    "meta_CSV.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>sha</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13761</th>\n",
       "      <td>3zturry3</td>\n",
       "      <td>dd63c8a6ff3ae72819472ca9eef5dfb0f13afb5e</td>\n",
       "      <td>PMC7089353</td>\n",
       "      <td>High-level expression of a human β-site APP cl...</td>\n",
       "      <td>Plastid transformation has to date been applie...</td>\n",
       "      <td>Youm, Jung Won; Jeon, Jae Heung; Kim, Hee; Min...</td>\n",
       "      <td>Transgenic Res</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12425</th>\n",
       "      <td>yi2l5bcu</td>\n",
       "      <td>7e4c7d38872c37923d5ba6e8da2c6b01b72f176d</td>\n",
       "      <td>PMC7080100</td>\n",
       "      <td>Review of plasmonic fiber optic biochemical se...</td>\n",
       "      <td>This paper presents a brief overview of the te...</td>\n",
       "      <td>Caucheteur, Christophe; Guo, Tuan; Albert, Jac...</td>\n",
       "      <td>Anal Bioanal Chem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>pd9lt4n2</td>\n",
       "      <td>dd969a7721176db21314930b62e62a37e902dae5</td>\n",
       "      <td>PMC4453572</td>\n",
       "      <td>Heparan Sulfate-Dependent Enhancement of Henip...</td>\n",
       "      <td>Nipah virus and Hendra virus are emerging, hig...</td>\n",
       "      <td>Mathieu, Cyrille; Dhondt, Kévin P.; Châlons, M...</td>\n",
       "      <td>mBio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5971</th>\n",
       "      <td>r46d5kdu</td>\n",
       "      <td>33310fc6d99fa6bbf3aa6160168f3acba6a736d7</td>\n",
       "      <td>PMC4728157</td>\n",
       "      <td>Roles of the hemagglutinin of influenza A viru...</td>\n",
       "      <td>Seasonal influenza epidemics and influenza pan...</td>\n",
       "      <td>Jiang, Shibo; Li, Runming; Du, Lanying; Liu, S...</td>\n",
       "      <td>Protein &amp; Cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50818</th>\n",
       "      <td>e93nu56p</td>\n",
       "      <td>adec4c54ca0073999de9e63c5806585d5ac2c358</td>\n",
       "      <td>PMC7116949</td>\n",
       "      <td>The ventilation of multiple-bed hospital wards...</td>\n",
       "      <td>Abstract Hospital and healthcare facilities ha...</td>\n",
       "      <td>Yau, Y.H.; Chandrasegaran, D.; Badarudin, A.</td>\n",
       "      <td>Building and Environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49765</th>\n",
       "      <td>iwv9lilo</td>\n",
       "      <td>1e90e5ac4f30837179cd3ff9f9f380cd4dcaeca8</td>\n",
       "      <td>PMC7117285</td>\n",
       "      <td>Characterization of turkey coronavirus from tu...</td>\n",
       "      <td>Abstract The present study was to characterize...</td>\n",
       "      <td>Lin, Tsang L.; Loa, Chien C.; Tsai, Shih C.; W...</td>\n",
       "      <td>Veterinary Microbiology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31306</th>\n",
       "      <td>jngjogrh</td>\n",
       "      <td>67de735e7e3f2e60bfd376d42819b00faa8bd95e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disidratazione acuta nel lattante</td>\n",
       "      <td>Il lattante al di sotto di un anno, e soprattu...</td>\n",
       "      <td>Hubert, P.</td>\n",
       "      <td>EMC - Urgenze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12060</th>\n",
       "      <td>m128nfhn</td>\n",
       "      <td>95cd65dbf317e24c13557dbf46ffbaa4c206f8be</td>\n",
       "      <td>PMC7019308</td>\n",
       "      <td>Isolation and Identification of Porcine Deltac...</td>\n",
       "      <td>Porcine deltacoronavirus (PDCoV) is a porcine ...</td>\n",
       "      <td>Qian, Shaoju; Jia, Xiangchao; Gao, Zitong; Zha...</td>\n",
       "      <td>Viruses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50715</th>\n",
       "      <td>r1vsvdz0</td>\n",
       "      <td>4a817cc21c19f64d48b5e0a9e062b934eec46955</td>\n",
       "      <td>PMC7126289</td>\n",
       "      <td>A novel method for making human monoclonal ant...</td>\n",
       "      <td>Abstract We have developed a B cell immortaliz...</td>\n",
       "      <td>Fraussen, J.; Vrolix, K.; Martinez-Martinez, P...</td>\n",
       "      <td>Journal of Autoimmunity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48650</th>\n",
       "      <td>k7ujru6t</td>\n",
       "      <td>b8f9525f63118ab787c2f81dc9fff88cba0eecc7</td>\n",
       "      <td>PMC7134557</td>\n",
       "      <td>Identification and functional characterization...</td>\n",
       "      <td>Abstract The helicase-like domain of the Bambo...</td>\n",
       "      <td>Han, Yu-Tsung; Hsu, Yau-Heiu; Lo, Chia-Wen; Me...</td>\n",
       "      <td>Virology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cord_uid                                       sha       pmcid  \\\n",
       "13761  3zturry3  dd63c8a6ff3ae72819472ca9eef5dfb0f13afb5e  PMC7089353   \n",
       "12425  yi2l5bcu  7e4c7d38872c37923d5ba6e8da2c6b01b72f176d  PMC7080100   \n",
       "5169   pd9lt4n2  dd969a7721176db21314930b62e62a37e902dae5  PMC4453572   \n",
       "5971   r46d5kdu  33310fc6d99fa6bbf3aa6160168f3acba6a736d7  PMC4728157   \n",
       "50818  e93nu56p  adec4c54ca0073999de9e63c5806585d5ac2c358  PMC7116949   \n",
       "...         ...                                       ...         ...   \n",
       "49765  iwv9lilo  1e90e5ac4f30837179cd3ff9f9f380cd4dcaeca8  PMC7117285   \n",
       "31306  jngjogrh  67de735e7e3f2e60bfd376d42819b00faa8bd95e         NaN   \n",
       "12060  m128nfhn  95cd65dbf317e24c13557dbf46ffbaa4c206f8be  PMC7019308   \n",
       "50715  r1vsvdz0  4a817cc21c19f64d48b5e0a9e062b934eec46955  PMC7126289   \n",
       "48650  k7ujru6t  b8f9525f63118ab787c2f81dc9fff88cba0eecc7  PMC7134557   \n",
       "\n",
       "                                                   title  \\\n",
       "13761  High-level expression of a human β-site APP cl...   \n",
       "12425  Review of plasmonic fiber optic biochemical se...   \n",
       "5169   Heparan Sulfate-Dependent Enhancement of Henip...   \n",
       "5971   Roles of the hemagglutinin of influenza A viru...   \n",
       "50818  The ventilation of multiple-bed hospital wards...   \n",
       "...                                                  ...   \n",
       "49765  Characterization of turkey coronavirus from tu...   \n",
       "31306                  Disidratazione acuta nel lattante   \n",
       "12060  Isolation and Identification of Porcine Deltac...   \n",
       "50715  A novel method for making human monoclonal ant...   \n",
       "48650  Identification and functional characterization...   \n",
       "\n",
       "                                                abstract  \\\n",
       "13761  Plastid transformation has to date been applie...   \n",
       "12425  This paper presents a brief overview of the te...   \n",
       "5169   Nipah virus and Hendra virus are emerging, hig...   \n",
       "5971   Seasonal influenza epidemics and influenza pan...   \n",
       "50818  Abstract Hospital and healthcare facilities ha...   \n",
       "...                                                  ...   \n",
       "49765  Abstract The present study was to characterize...   \n",
       "31306  Il lattante al di sotto di un anno, e soprattu...   \n",
       "12060  Porcine deltacoronavirus (PDCoV) is a porcine ...   \n",
       "50715  Abstract We have developed a B cell immortaliz...   \n",
       "48650  Abstract The helicase-like domain of the Bambo...   \n",
       "\n",
       "                                                 authors  \\\n",
       "13761  Youm, Jung Won; Jeon, Jae Heung; Kim, Hee; Min...   \n",
       "12425  Caucheteur, Christophe; Guo, Tuan; Albert, Jac...   \n",
       "5169   Mathieu, Cyrille; Dhondt, Kévin P.; Châlons, M...   \n",
       "5971   Jiang, Shibo; Li, Runming; Du, Lanying; Liu, S...   \n",
       "50818       Yau, Y.H.; Chandrasegaran, D.; Badarudin, A.   \n",
       "...                                                  ...   \n",
       "49765  Lin, Tsang L.; Loa, Chien C.; Tsai, Shih C.; W...   \n",
       "31306                                         Hubert, P.   \n",
       "12060  Qian, Shaoju; Jia, Xiangchao; Gao, Zitong; Zha...   \n",
       "50715  Fraussen, J.; Vrolix, K.; Martinez-Martinez, P...   \n",
       "48650  Han, Yu-Tsung; Hsu, Yau-Heiu; Lo, Chia-Wen; Me...   \n",
       "\n",
       "                        journal  \n",
       "13761            Transgenic Res  \n",
       "12425         Anal Bioanal Chem  \n",
       "5169                       mBio  \n",
       "5971             Protein & Cell  \n",
       "50818  Building and Environment  \n",
       "...                         ...  \n",
       "49765   Veterinary Microbiology  \n",
       "31306             EMC - Urgenze  \n",
       "12060                   Viruses  \n",
       "50715   Journal of Autoimmunity  \n",
       "48650                  Virology  \n",
       "\n",
       "[5000 rows x 7 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are 9,524 items in the comm_use_subset pdf list\n",
    "#There are 9,148 items in the comm_use_subset pmc list\n",
    "#There are 2,490 items in the noncomm_use_subset pdf list\n",
    "#There are 2,217 items in the noncomm_use_subset pmc list\n",
    "#There are 26,505 items in the custom_license pdf list\n",
    "#There are 7,802 items in the custom_license pmc list\n",
    "#There are 1,625 items in the biorxiv_medrxiv pdf list\n",
    "\n",
    "#That's a total of 40,144 pdf papers (with sha names)\n",
    "#Using the sha code, we found 31,646 papers.\n",
    "#So, 8,498 items were not found with the sha code, that's fine.\n",
    "\n",
    "#We can now take a random sample of these 31,000 papers to generate a much smaller list of 5000.\n",
    "\n",
    "meta_sample = meta_CSV.sample(n=5000, random_state = 666) #because it's funny\n",
    "meta_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Alzheimer disease (AD) is a widespread senile dementia characterized by the progressive formation of insoluble amyloid plaques in the brain. The amyloid plaques comprise a 4 kDa b-amyloid protein (Ab) derived by sequential proteolysis of the amyloid precursor protein (APP) through the activities of band c-secretases (Tanahashi and Tabira 2007; McConlogue et al. 2007 ). These enzymes are considered to be therapeutic targets important in the treatment of AD (Pastarino et al. 2004 ). However, c-secretase is not an ideal therapeutic target because it is also responsible for the cleavage of a number of other important cellular proteins involved in signaling processes. Thus, b-secretase, or b-site APP cleaving enzyme (BACE), is a more attractive therapeutic target (Parsons and Austen 2007) . Chang et al. (2007) showed that immunization of transgenic AD mice (Tg2576) with BACE resulted in Ab reduction and cognitive improvement. They suggested that immunization may have resulted in anti-BACE antibodies penetrating the blood-brain barrier (BBB) and binding to BACE located on neuronal surfaces, thereby inhibiting enzyme activity. When BACE-antibody complex is endocytosed, BACE cleavage of APP is inhibited by the bound antibody, resulting in a decrease in Ab production. Consequently, immunization with BACE to produce antibodies that neutralize b-secretase activity leading to a reduction in Ab is being considered as a new therapeutic concept for AD. Previously, it was shown that although BACE knockout mice have reduced Ab production, they do not exhibit any abnormal phenotypes (Luo et al. 2001) . The BACE gene was cloned and characterized in 1999 (Vassar et al. 1999) , and various BACE constructs have been expressed in insect (Bruinzeel et al. 2002) , mammalian , and E. coli cells (Sardana et al. 2004; Tomasselli et al. 2008) . For the production of pharmaceutical proteins, chloroplast transformation has advantages over nuclear transformation approaches, such as high-level transgene expression (Daniell et al. 2002) , multi-gene engineering in a single transformation event (De Cosa et al. 2001; Jeong et al. 2004) , transgene containment via maternal inheritance (Daniell et al. 2002) , and lack of gene silencing and position effects due to sitespecific integration (De Cosa et al. 2001; Daniell et al. 2002; Lee et al. 2003; Watson et al. 2004 ). The recombinant protein yield can be dramatically increased, especially in tobacco, because a leaf cell contains as many as 100 chloroplasts, with up to 100 genomes each; a total of approximately 10,000 plastome copies per cell. Biopharmaceutical compounds, such as human somatotropin (Staub et al. 2000) , human papillomavirus L1 protein (Fernandez-San Millan et al. 2008) , the B-subunit of the cholera toxin (CTB) (Daniell et al. 2001a) , and the tetanus toxin (Tregoning et al. 2005) , have been expressed at high levels (4-25% of TSP). Additionally, environmental concerns regarding transgene escape via pollen from nuclear transgenic plants is abrogated by chloroplast transformation due to the maternal inheritance of plastids in most cultivated plants ( Molina et al. 2004) . Recently, in our laboratory, human BACE protein was expressed in nuclear transformed transgenic potato and tomato plants in an attempt to develop a plant-derived AD vaccine (Youm et al. unpublished data) . Following analysis of these transgenic plants, the human BACE was shown to accumulate to levels of 0.12-0.19% of total soluble protein (TSP). Low levels of heterologous protein accumulation in plants is regarded as one of the limiting factors in the commercialization of plant-derived vaccines. Here, we introduced a human BACE gene into the plastome of tobacco plants to increase transgenic protein accumulation. Tobacco plants produce a large biomass, yielding approximately 170 metric tons of biomass per hectare (Fischer and Emans 2000) . Tobacco, a nonfood and non-feed crop, is selfpollinating, thus minimizing transgene escape. Most importantly, we chose tobacco because it is a model plant for plastid transformation and is closely related to potato and tomato plants. In the current study, we report on the integration and expression of the human BACE gene in the plastome. The accumulation levels and antigenicity of the BACE protein derived from transplastomic tobacco were analyzed by western blot or ELISA. The immunogenic responses of tobacco plastid-derived BACE were observed by oral application in test mice. We discuss the potential use of plastid-derived BACE antigen as a new oral vaccine against AD. This may be the first step toward developing a plant-based vaccine against AD. Tobacco seeds (Nicotiana tabacum L. cv. Xanthi) were surface sterilized with 70% ethanol for 10 min followed by 15 min in 1.0% sodium hypochlorite. Seeds were then washed three times in sterile water before being placed in petri dishes containing solid MS tissue culture medium (Murashige and Skoog 1962) supplemented with 3% sucrose and solidified with 0.8% agar, pH 5.8, at 25°C under long-day conditions (16 h light/8 h dark) with 45 lmol photons m -2 s -1 white light. Leaves from 8-12weeks-old plants were used for bombardment. In accordance with the previously published methods used to construct the plastid transformation vector pTIG (Jeong et al. 2004 ), we constructed a new vector for dicistronic expression of the aadA and human BACE genes under the control of the plastid rrn promoter (only PEP-type) with identical sequence reported by Svab and Maliga (1993) . Human BACE was amplified from the pET19b/BACE22460 plasmid (kindly provided by Dr. Inhee Mook-Jung at Seoul National University, Korea) with two primers: forward primer (5 0 -TTtctagaAGGAGGTATAACA ATG ACC CAG CAC GGC ATC CGG-3 0 ), which included an XbaI restriction site and a start codon (underlined); reverse primer (5 0 -GCCCtctagaTTA ATA GGC TAT GGT CAT GAG-3 0 ), which included an XbaI restriction site and a stop codon (underlined). A single amplification product of the expected size of BACE was purified and subcloned into the TOPO TA plasmid (Invitrogen, San Diego, CA, USA) and confirmed by DNA sequencing. The BACE gene was connected by a linker sequence (5 0 -AGA AGG AGG TAT AAC A-3 0 ) including the rbs (consensus ribosome binding site GGAGG to enhance translation of BACE) to the 3 0 end of the antibiotic resistance gene aadA. In summary, the construct included the following sequences: the border sequences with trnI and trnA genes, which are homologous to the trnI and trnA genes in the inverted repeat region of the tobacco plastome; Prrn, the constitutive promoter of 16S rRNA; the aminoglycoside 3 0 -adenylyltransferase (aadA), conferring resistance to both spectinomycin and streptomycin; the rbs fused to the BACE coding sequence; and the 3 0 UTR of the psbA gene. The final vector is referred to as CtVBACE (Fig. 1a ). The chloroplast transformation method used in this study was published previously by Jeong et al. (2004) . Leaf blades were placed abaxial side up on MS medium supplemented with 4.44 lM 6-benzylaminopurine and 0.54 lM a-naphthalaneacetic acid (shoot-inducing medium) in plastic petri dishes (87 9 15 mm). Leaf blades were bombarded by gold particles (0.6 lm) coated with vector DNA at 1,100 psi and 28 inches Hg using a biolistic particle delivery system (PDS 1000/He; Bio-Rad, Hercules, CA, USA). Following particle bombardment, the tissues were incubated in the dark at 25°C for 48 h on shoot-inducing media. After 2 day, the leaves were dissected into sections and then cultured for antibiotic selection and regeneration, until shoot development was induced. Homoplasmic transplastomic lines were selected after three rounds of regeneration under selection conditions, and transferred onto MS basal medium containing 500 mg l -1 spectinomycin to induce rooting. Transplastomic plants were transferred to pots and grown in a greenhouse to evaluate the phenotype. PCR was performed on primary regenerated shoots to determine transgene integration into the plastome. PCR primers FI (5 0 -CCGTAGG TGCGATGATTTACTTC-3 0 ) and RA (5 0 -AGAGT CTTTCAGTGGCACGTTTC-3 0 ), which anneal to regions of the trnI gene and the trnA gene, respectively, were used to confirm transgene integration into the N. tabacum plastome. PCRs were carried out in a DNA thermal cycler (GeneAmp PCR system 9700; Applied Biosystems, Carlsbad, CA, USA) under the following conditions: 94°C for 5 min, followed by 30 cycles of 94°C for 1 min, 55°C for 1 min, and 72°C for 2 min, with a final 10 min extension at 72°C. Total genomic DNA was isolated from tobacco leaf tissues (120 mg) using the DNeasy Plant Mini Kit (Qiagen, Valencia, CA, USA) and following the manufacturer's instructions. Approximately 5 lg of genomic DNA was digested with BglII, separated on 0.8% (w/v) agarose gels, and blotted onto nylon membranes (Zeta-Probe GT genomic tested blotting membranes; Bio-Rad) in 109 SSC. For probes, a 0.15 kb trnA-specific DNA fragment was amplified by PCR using CtVBACE as a template and trnA F1 (5 0 -TGCGATTACGGGTTGGATGT-3 0 ) and trnA R1 (5 0 -GTTCTTGACAGCCCATCTTT-3 0 ) primers, and a 0.33 kb BACE-specific DNA fragment was prepared from restriction digestion of the BACE gene with XbaI and BstEII. The two probes were then labeled with [ 32 P] dCTP using the Random Primed DNA Labeling kit (Roche Diagnostics, Mannheim, Germany). Prehybridization and hybridization were carried out overnight in 0.25 M sodium phosphate (pH 7.2) and 7% (w/v) SDS solution at 65°C. The membranes were washed in 20 mM sodium phosphate (pH 7.2) and 5% (w/v) SDS at 65°C for 15 min, then washed in 20 mM sodium phosphate (pH 7.2) and 1% (w/v) SDS at 65°C for 15 min. The membranes were exposed using an Imaging Plate (Fujifilm, Tokyo, Japan) at room temperature (RT). Total RNA was extracted from leaves of wild-type (Wt) and transplastomic tobacco plants using the RNeasy Plant Mini Kit (Qiagen) according to the manufacturer's instructions. RNA (5 lg) was denatured with formaldehyde and formamide, fractionated in a 1% agarose gel using 3-(N-morpholino) propanesulfonic acid (MOPS) buffer, and then blotted onto nylon membranes (Zeta-Probe GT genomic tested blotting membranes; Bio-Rad) in 209 SSC overnight. A 0.33 kb BACE-specific DNA fragment (probe) was prepared from restriction digestion of the BACE gene with XbaI and BstEII. The probe was labeled with [a-32 P] dCTP. Prehybridization, hybridization at 65°C overnight, and washing of the membrane was carried out according to the manufacturer's instructions. Total soluble proteins (TSP) were extracted from leaves of Wt and transplastomic tobacco plants by homogenization in cold protein extraction buffer containing 19 PBS (pH 7.4), 10 mM EDTA, 1 mM proteinase inhibitor cocktail, 0.1% Triton X-100, and 5 mM b-mercaptoethanol (1 g of fresh weight ml -1 ). The extract was centrifuged for 20 min at 13,000 rpm and the protein concentration was quantified by the Bradford method (Bradford 1976) . After separation by 10% SDS-PAGE and transfer to PVDF (Millipore, Bedford, MA, USA), the BACE antigen protein was detected with a specific anti-BACE polyclonal Quantitative ELISA assay of tobacco plastid-derived BACE The levels of BACE protein in transplastomic plants were determined using a quantitative ELISA analysis. The ELISA plates (Nunc-Immuno Maxisorp, Roskilde, Denmark) were coated with TSP from Wt or transplastomic lines B5, C7, E10, and H3, respectively, and incubated overnight at 4°C. The background was blocked with 5% skim milk in PBST (200 ll per well), and the plate was incubated with a 1:1,000 dilution of goat anti-BACE (Santa Cruz Biotech Inc., Santa Cruz, CA, USA) polyclonal (100 ll per well) for 2 h at RT, and then incubated with horseradish peroxidase (HRP)-conjugated secondary antibody (Sigma). The plates were finally incubated with the chemiluminescent substrate, TMB peroxidase substrate solution (Pierce, Rockford, USA), for 30 min at RT in the dark to maximize the reaction rate. After the confirmation of sufficient color development, reactions were stopped with 2.5 M H 2 SO 4 . The plates were then assessed for absorbance at 492 nm. The amount of BACE protein in TSPs (lg antigen ml -1 TSP) was estimated by comparing with standard concentrations of E.coli-derived BACE. Protein preparation for mouse administration Freshly harvested tobacco leaves (500 mg) were quickly powdered in liquid nitrogen, and TSP was extracted with ice-cold buffer containing phosphatebuffered saline (PBS; Sigma), 1 mM EDTA, 0.1% Triton X-100, and 19 proteinase inhibitor (Roche diagnostics). After homogenization, the samples were centrifuged twice at 12,000 rpm for 20 min at 4°C. The supernatant was concentrated by automatic speedvac (AS160; Savant, NY, USA) into 0.5 ml, the appropriate volume for a single dose to mice. Vaccination of Balb/c mice with tobacco plastidderived BACE Balb/c mice of both sexes, weighing 24-25 g, were used in the immunization experiments. The mice were gavaged with the 0.5 ml extracts from transplastomic tobacco line CtVBACE-B5 (five mice) or Wt tobacco plants (five mice) plus 10 lg of Cholera Toxin (CT, Sigma) on days 0, 7, and 14. Immunizations were performed using a 1 ml syringe fitted with a gavage needle. Prior to the oral immunizations, 0.2 ml of sodium bicarbonate was applied by gastric gavage to each of the mice to neutralize stomach acidity. Before the initial immunization with the plastid-derived BACE (day 0) and after the third primary immunization (day 14), blood was drawn from the orbital plexus of each mouse to obtain antiserum samples. Each mouse was given an intraperitoneal booster with 10 lg of yeast-derived recombinant BACE emulsified in alum two weeks after the third administration (day 28). Sera were collected from the mice a week after boosting (day 35), and all blood samples were analyzed by ELISA. Most of the procedures were performed as previously described by Youm et al. (2005) . Briefly, flat-bottom ELISA plates were coated overnight at 4°C with antigen (0.1 lg well -1 or 1.0 lg well -1 BACE with 0.05 M carbonate-bicarbonate buffer [pH 9.6]). The coated plates were incubated for 2 h at RT with serum samples diluted 1:100 in blocking buffer. The plates were then incubated for 2 h at RT with antimouse IgG-conjugated horseradish peroxidase (secondary antibody) diluted 1:1,000 in blocking buffer. Tetra methyl benzidine (TMB) substrate 100 ll (Pierce) was added to visualize the color development for 30 min and H 2 O 2 was added to stop the reaction at RT. Developed ELISA plates were read on a Microplate reader (Model 680, Bio-Rad). The 1.3 kb human BACE gene (coding for amino acids 22-460 without the transmembrane domain sequence) was placed under the transcriptional control of Prrn, the constitutive promoter of 16S rRNA. Prrn is the strong plastid rRNA operon promoter (Vera and Sugiura 1995) . This gene construct, called CtVBACE, was introduced into tobacco chloroplasts via a biolistic particle delivery system, and shoots were observed on explants after 5-6 weeks on selection medium. Eight independent green primary-shoots were selected after plastid transformation of tobacco using the vector CtVBACE. The eight plant lines regenerated on selection medium were analyzed by PCR using primers designed to detect the aadA::BACE gene integrated into the plastome. A 0.3 kb PCR-amplified product was detected in all plants, including Wt ones, and a 3.0 kb PCR-amplified product was detected in the eight transformed primary tobacco lines but not in Wt tobacco (Fig. 1b) . This indicated that the gene of interest had integrated into the plastome of the transgenic tobacco and that the lines were heteroplasmic for the transgene insertion. Four homoplasmic lines (B5, C7, E10, and H3) were obtained following two further rounds of regeneration under selection from four primary regenerated shoots (2, 3, 5, and 7, respectively). Correct integration of the BACE gene into the plastome of the four homoplasmic lines was confirmed by Southern blot analysis. The [ 32 P] dCTP-labeled trnA probe hybridized to a 4.7 kb BglII fragment in the untransformed control and to a 7.4 kb fragment in the transplastomic tobacco lines (Fig. 2a) . The blot was probed with the BACE coding region probe which only hybridized the 7.4 kb BglII fragment in the transgenic lines (Fig. 2b) . These results confirmed that the human BACE gene had integrated into the plastome of the transformants through homologous recombination in the trnI-trnA region. BACE gene transcription in the chloroplast was analyzed by northern blot analysis. The expected length of the aadA::BACE dicistronic transcript was approximately 2.0 kb (0.7 kb for aadA and 1.3 kb for BACE). The BACE probe detected a major transcript of approximately 2 kb, indicating that the BACE gene was dicistronically expressed in transplastomic plants (Fig. 2c) . A second major transcript (4.7 kb) hybridizing to the BACE gene probe is attributed to transgene transcription via read-through from the endogenous 16S rRNA promoter (Jeong et al. 2004; Sugita and Sugiura 1996) . The polyclonal anti-BACE antiserum recognized a protein of the expected size for BACE in all four plastid transformed lines (48 kDa, Fig. 3a) . No protein was detected in Wt tobacco using this antibody (Fig. 3a) . ELISA analysis was used to quantify the level of BACE protein accumulation in the four transgenic lines. Transplastomic lines B5, C7, E10, and H3 showed significant levels of BACE protein accumulation estimated at 21. 05, 22.51, 20.53, and 19 .38 lg mg -1 TSP, respectively (Fig. 3b) . As expected, the Wt samples showed no change in color development on the ELISA, indicating the absence of BACE protein. The amount of BACE protein produced in each plant line was calculated as the percent of BACE protein detected in triplicate ELISA compared to the TSP. Accordingly, BACE protein accumulation (a and b) and northern (c) blot. Genomic DNA (5 lg) isolated from non-transformed wild-type plant (Wt) and transplastomic tobacco lines (1-4 correspond to lines B5, C7, E10, and H3) was digested with BglII. DNA blot hybridized with trnA probe (a) and BACE probe (b). c Northern blot analysis of CtVBACE mRNA in transplastomic tobacco plants. Total RNA was extracted from Wt and transplastomic tobacco plants. RNA blot hybridized with BACE probe. Loading was monitored by methylene blue staining of the blot was estimated at 4.8-5.6 lg 100 mg -1 fresh weight in the transplastomic lines. The transplastomic line B5 was used for further oral administration. Immune response of mice to tobacco chloroplast-derived BACE To evaluate the immune response of mice to chloroplast-derived BACE protein, mice were immunized with BACE protein from the transplastomic tobacco line CtVBACE-B5 or from Wt tobacco as a control. Mice were orally gavaged with *25 lg of BACE protein, and then boosted on day 28 with 10 lg of yeast-derived recombinant BACE emulsified in alum. To determine the anti-BACE response, sera was collected before antigen administration as a control, after the third administration, and after the booster. Sera from mice immunized with transplastomic tobacco protein extract had a slight response as measured by ELISA after the third administration, and there was a significant increase in serum reactivity against BACE after boosting (Fig. 4a ). Mice inoculated with Wt tobacco extract did not produce any BACE-specific antibodies until boosting. During immunization with plastid-derived BACE antigen, none of the mice died, and weight gain was the same as those inoculated with control extracts (Fig. 4b) . We checked the growth pattern of normal, means non-immunized, mice as control group. There was no difference in growth between the non-immunized mice (data not shown) and those immunized with Wt tobacco extracts (Fig. 4b) . These findings indicate that oral delivery of plastid-derived BACE was immunogenic in mice. Fig. 4 a Blood serum anti-BACE antibody response to tobacco plastid-derived BACE in Balb/c mice after oral immunization. Mice were gavaged with extracts from Wt tobacco plants or from the transplastomic tobacco line CtVBACE-B5 with Cholera Toxin as an adjuvant on days 0, 7, and 14. Mice sera were collected before inoculation (days 0) (h); after the third primary immunization (days 14) (Q); and after the booster (day 35) (j). Sera were analyzed by ELISA for induced antibodies specific to BACE. Each bar respresents the average of five immunized mice ± standard error. b Effect of oral immunization of plastid-derived BACE on the body weight in Balb/c mice. The three administrations of plastidderived BACE are indicated by solid-line arrows, and intraperitoneal booster with 10 lg of yeast-derived recombinant BACE is indicated by a dotted-line arrow. Blood was drawn from the orbital plexus of each mouse on days 0, 14 and 35, to obtain antiserum samples (r) The most likely cause of AD is neuronal cell death induced by the accumulation of toxic Ab protein in the brain. Thus, a therapeutic agent that could fundamentally inhibit the degeneration of neurons by inhibiting the production and toxicity of Ab would be a highly effective means of preventing and treating AD. Ab is produced by the cleavage actions of bsecretase (BACE) and c-secretase during an amyloidogenic metabolic process. b-secretase inhibition may prevent dementia; this would be more efficient and economical than removing previously formed Ab. Therefore, b-secretase inhibition through vaccination is presently receiving increased attention worldwide (McConlogue et al. 2007 ). In the present study, attempts were made to achieve high level expression of human BACE in tobacco plants via chloroplast transformation. Following particle bombardment with the CtVBACE construct and after three rounds of selection, four transplastomic tobacco lines were obtained. Western blot confirmed that plastid-derived BACE protein was recognized by an antibody specific to human BACE, and ELISA analysis estimated BACE protein accumulation in transgenic lines at approximately 2.0% of TSP. This is much higher than the BACE yield from nuclear transformed potato tuber or tomato fruit, estimated at 0.12-0.19% of TSP (Youm et al. unpublished data) . However, the level of plastid-based BACE accumulation achieved in this study is lower than what can be expected from chloroplast transformation. The chimeric CTB-2L21 protein was accumulated in tobacco chloroplasts to levels up to 31.1% of TSP (Molina et al. 2004) , and the tetanus fragment C toxin to levels of 10-25% of TSP (Tregoning et al. 2005) . Furthermore, PA/g for anthrax was accumulated in plastid-transformed plants at levels up to 2.5 mg g -1 fresh weight (Watson et al. 2004 ). However, other antigens such as FMDV VP1 protein (2.0-3.0% of TSP [Li et al. 2006a, b] ), HPV L1 (up to 1.5% of TSP [Lenzi et al. 2008 ]), and SARS-CoV S1 protein (approximately 0.2% of TSP [Li et al. 2006a, b] ) accumulated in transplastomic plants at levels that were similar to, or lower than, those achieved for BACE protein in our study. These markedly different expression levels may be due to the type of antigen being expressed, post-transcriptional events and/or protein stability in plastids. Herz et al. (2005) reported that protein expression in the plastid depended on several factors including the types of transformation vectors, promoter and translational control elements used, and external factors like plant age or light intensity. Therefore, the levels of BACE expression achieved in this study may be attributable to some of these various factors. As expected, in stable transplastomic tobacco plants, immunoblot analyses detected a protein that is smaller than the E. coli-derived BACE. The E. coli-derived BACE has a molecular mass of *60 kDa, whereas the plastid-derived BACE has a 48 kDa since the transmembrane domain was removed. From this result, we could estimate that the protein size of the chloroplast-derived BACE was not changed due to post-translational process. Chloroplasts have the ability to process eukaryotic proteins, including correct folding of subunits and formation of disulfide bridges (Staub et al. 2000; Daniell et al. 2001b) , result in fully functional recombinant protein. In the present study, although we have not analyzed the glycosylation status of the chloroplast-derived BACE protein, the recombinant BACE was immunologically active. BACE expression in tobacco chloroplasts did not affect plant growth rate, flowering, or seed set, and there was no apparent morphological difference between transplastomic and Wt tobacco plants in the greenhouse (data not shown). This observation concurs with previous reports where transplastomic tobacco plants expressing CTB (Daniell et al. 2001a) or ETEC (Kang et al. 2004) had no pleiotropic effects compared to Wt plants. Our results show that mice administered with extracts from transplastomic tobacco exhibited a slight induction of primary anti-BACE antibody after three inoculations. However, there was a significant increase in BACE antiserum after boosting compared to the primary antibody response, suggesting that memory immune cells were established as a result of oral immunization. An immediate and strong secondary antibody induction was observed in several studies of small animals that received a boost of commercial vaccines (Richter et al. 2000; Kong et al. 2001) . Induction of specific-Ab antibodies by plantderived Ab was reported in a previous study (Youm et al. 2005 (Youm et al. , 2008 . Much work remains to confirm the feasibility of plastid-produced BACE as an AD vaccine, including characterization of plastid-produced human BACE, purification and processing of BACE, and immunization of a disease model animal. In conclusion, we successfully expressed human BACE in transplastomic tobacco plants at levels higher than those expressed in transgenic potato or tomato plants. Moreover, this candidate plant-derived antigen was immunogenic via oral route delivery in mice and may be a useful model for developing a broad-spectrum plant-based vaccine against AD.\""
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Excellent. Now we need to read in the .json files in a way that allows us to access the text, so we can tokenize it.\n",
    "#Let's try reading in only 1 .json file first.\n",
    "#We will use glob.glob to recursively search for the correct files. Once it is found, we will read in that json file.\n",
    "\n",
    "\n",
    "#When ready, I'll add a for loop here. to parse all the files in a batch. Instead of 0, it'll be i.\n",
    "sha = meta_sample.iloc[0,1] #meta_sample.iloc[i,1]\n",
    "filename = sha + \".json\"\n",
    "globstring = os.path.abspath(os.curdir) + '\\\\docs\\\\**\\\\' + filename\n",
    "filepath = glob.glob(globstring, recursive = True)\n",
    "\n",
    "with open(filepath[0], 'r') as file:\n",
    "    myjson = json.load(file)\n",
    "    file.close()\n",
    "\n",
    "#myjson[\"abstract\"][0][\"text\"]\n",
    "#myjson['body_text'][1][\"text\"] #Need to loop through the len(myjson['body_text'])\n",
    "#len(myjson['body_text']) #25\n",
    "full_text = \"\"\n",
    "for x in range(0,len(myjson['body_text'])):\n",
    "    if x == len(myjson['body_text'])-1:\n",
    "        full_text = full_text + myjson['body_text'][x][\"text\"]\n",
    "    else:      \n",
    "        full_text = full_text + myjson['body_text'][x][\"text\"] + \" \"\n",
    "               \n",
    "full_text\n",
    "\n",
    "#print(json.dumps(myjson, indent = 4))\n",
    "\n",
    "#myjson['body']\n",
    "#Cool. Got my json file read in. Now I need to concatonate all the 'abstract', text' and 'body_text', 'text' to two very large\n",
    "#entries in a list.\n",
    "#The goal is to create a dataframe in the end, which we can work with more easily.\n",
    "#My vision is something like:\n",
    "#    sha/paper_id     title              abstract_text           body_text\n",
    "#    1200128asfd34    High-level...      'We found that ...'    'intro. Planarians have...'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package json:\n",
      "\n",
      "NAME\n",
      "    json\n",
      "\n",
      "MODULE REFERENCE\n",
      "    https://docs.python.org/3.8/library/json\n",
      "    \n",
      "    The following documentation is automatically generated from the Python\n",
      "    source files.  It may be incomplete, incorrect or include features that\n",
      "    are considered implementation detail and may vary between Python\n",
      "    implementations.  When in doubt, consult the module reference at the\n",
      "    location listed above.\n",
      "\n",
      "DESCRIPTION\n",
      "    JSON (JavaScript Object Notation) <http://json.org> is a subset of\n",
      "    JavaScript syntax (ECMA-262 3rd edition) used as a lightweight data\n",
      "    interchange format.\n",
      "    \n",
      "    :mod:`json` exposes an API familiar to users of the standard library\n",
      "    :mod:`marshal` and :mod:`pickle` modules.  It is derived from a\n",
      "    version of the externally maintained simplejson library.\n",
      "    \n",
      "    Encoding basic Python object hierarchies::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> json.dumps(['foo', {'bar': ('baz', None, 1.0, 2)}])\n",
      "        '[\"foo\", {\"bar\": [\"baz\", null, 1.0, 2]}]'\n",
      "        >>> print(json.dumps(\"\\\"foo\\bar\"))\n",
      "        \"\\\"foo\\bar\"\n",
      "        >>> print(json.dumps('\\u1234'))\n",
      "        \"\\u1234\"\n",
      "        >>> print(json.dumps('\\\\'))\n",
      "        \"\\\\\"\n",
      "        >>> print(json.dumps({\"c\": 0, \"b\": 0, \"a\": 0}, sort_keys=True))\n",
      "        {\"a\": 0, \"b\": 0, \"c\": 0}\n",
      "        >>> from io import StringIO\n",
      "        >>> io = StringIO()\n",
      "        >>> json.dump(['streaming API'], io)\n",
      "        >>> io.getvalue()\n",
      "        '[\"streaming API\"]'\n",
      "    \n",
      "    Compact encoding::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> mydict = {'4': 5, '6': 7}\n",
      "        >>> json.dumps([1,2,3,mydict], separators=(',', ':'))\n",
      "        '[1,2,3,{\"4\":5,\"6\":7}]'\n",
      "    \n",
      "    Pretty printing::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> print(json.dumps({'4': 5, '6': 7}, sort_keys=True, indent=4))\n",
      "        {\n",
      "            \"4\": 5,\n",
      "            \"6\": 7\n",
      "        }\n",
      "    \n",
      "    Decoding JSON::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> obj = ['foo', {'bar': ['baz', None, 1.0, 2]}]\n",
      "        >>> json.loads('[\"foo\", {\"bar\":[\"baz\", null, 1.0, 2]}]') == obj\n",
      "        True\n",
      "        >>> json.loads('\"\\\\\"foo\\\\bar\"') == '\"foo\\x08ar'\n",
      "        True\n",
      "        >>> from io import StringIO\n",
      "        >>> io = StringIO('[\"streaming API\"]')\n",
      "        >>> json.load(io)[0] == 'streaming API'\n",
      "        True\n",
      "    \n",
      "    Specializing JSON object decoding::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> def as_complex(dct):\n",
      "        ...     if '__complex__' in dct:\n",
      "        ...         return complex(dct['real'], dct['imag'])\n",
      "        ...     return dct\n",
      "        ...\n",
      "        >>> json.loads('{\"__complex__\": true, \"real\": 1, \"imag\": 2}',\n",
      "        ...     object_hook=as_complex)\n",
      "        (1+2j)\n",
      "        >>> from decimal import Decimal\n",
      "        >>> json.loads('1.1', parse_float=Decimal) == Decimal('1.1')\n",
      "        True\n",
      "    \n",
      "    Specializing JSON object encoding::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> def encode_complex(obj):\n",
      "        ...     if isinstance(obj, complex):\n",
      "        ...         return [obj.real, obj.imag]\n",
      "        ...     raise TypeError(f'Object of type {obj.__class__.__name__} '\n",
      "        ...                     f'is not JSON serializable')\n",
      "        ...\n",
      "        >>> json.dumps(2 + 1j, default=encode_complex)\n",
      "        '[2.0, 1.0]'\n",
      "        >>> json.JSONEncoder(default=encode_complex).encode(2 + 1j)\n",
      "        '[2.0, 1.0]'\n",
      "        >>> ''.join(json.JSONEncoder(default=encode_complex).iterencode(2 + 1j))\n",
      "        '[2.0, 1.0]'\n",
      "    \n",
      "    \n",
      "    Using json.tool from the shell to validate and pretty-print::\n",
      "    \n",
      "        $ echo '{\"json\":\"obj\"}' | python -m json.tool\n",
      "        {\n",
      "            \"json\": \"obj\"\n",
      "        }\n",
      "        $ echo '{ 1.2:3.4}' | python -m json.tool\n",
      "        Expecting property name enclosed in double quotes: line 1 column 3 (char 2)\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    decoder\n",
      "    encoder\n",
      "    scanner\n",
      "    tool\n",
      "\n",
      "CLASSES\n",
      "    builtins.ValueError(builtins.Exception)\n",
      "        json.decoder.JSONDecodeError\n",
      "    builtins.object\n",
      "        json.decoder.JSONDecoder\n",
      "        json.encoder.JSONEncoder\n",
      "    \n",
      "    class JSONDecodeError(builtins.ValueError)\n",
      "     |  JSONDecodeError(msg, doc, pos)\n",
      "     |  \n",
      "     |  Subclass of ValueError with the following additional properties:\n",
      "     |  \n",
      "     |  msg: The unformatted error message\n",
      "     |  doc: The JSON document being parsed\n",
      "     |  pos: The start index of doc where parsing failed\n",
      "     |  lineno: The line corresponding to pos\n",
      "     |  colno: The column corresponding to pos\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      JSONDecodeError\n",
      "     |      builtins.ValueError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, msg, doc, pos)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.ValueError:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class JSONDecoder(builtins.object)\n",
      "     |  JSONDecoder(*, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, strict=True, object_pairs_hook=None)\n",
      "     |  \n",
      "     |  Simple JSON <http://json.org> decoder\n",
      "     |  \n",
      "     |  Performs the following translations in decoding by default:\n",
      "     |  \n",
      "     |  +---------------+-------------------+\n",
      "     |  | JSON          | Python            |\n",
      "     |  +===============+===================+\n",
      "     |  | object        | dict              |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | array         | list              |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | string        | str               |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | number (int)  | int               |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | number (real) | float             |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | true          | True              |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | false         | False             |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | null          | None              |\n",
      "     |  +---------------+-------------------+\n",
      "     |  \n",
      "     |  It also understands ``NaN``, ``Infinity``, and ``-Infinity`` as\n",
      "     |  their corresponding ``float`` values, which is outside the JSON spec.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, strict=True, object_pairs_hook=None)\n",
      "     |      ``object_hook``, if specified, will be called with the result\n",
      "     |      of every JSON object decoded and its return value will be used in\n",
      "     |      place of the given ``dict``.  This can be used to provide custom\n",
      "     |      deserializations (e.g. to support JSON-RPC class hinting).\n",
      "     |      \n",
      "     |      ``object_pairs_hook``, if specified will be called with the result of\n",
      "     |      every JSON object decoded with an ordered list of pairs.  The return\n",
      "     |      value of ``object_pairs_hook`` will be used instead of the ``dict``.\n",
      "     |      This feature can be used to implement custom decoders.\n",
      "     |      If ``object_hook`` is also defined, the ``object_pairs_hook`` takes\n",
      "     |      priority.\n",
      "     |      \n",
      "     |      ``parse_float``, if specified, will be called with the string\n",
      "     |      of every JSON float to be decoded. By default this is equivalent to\n",
      "     |      float(num_str). This can be used to use another datatype or parser\n",
      "     |      for JSON floats (e.g. decimal.Decimal).\n",
      "     |      \n",
      "     |      ``parse_int``, if specified, will be called with the string\n",
      "     |      of every JSON int to be decoded. By default this is equivalent to\n",
      "     |      int(num_str). This can be used to use another datatype or parser\n",
      "     |      for JSON integers (e.g. float).\n",
      "     |      \n",
      "     |      ``parse_constant``, if specified, will be called with one of the\n",
      "     |      following strings: -Infinity, Infinity, NaN.\n",
      "     |      This can be used to raise an exception if invalid JSON numbers\n",
      "     |      are encountered.\n",
      "     |      \n",
      "     |      If ``strict`` is false (true is the default), then control\n",
      "     |      characters will be allowed inside strings.  Control characters in\n",
      "     |      this context are those with character codes in the 0-31 range,\n",
      "     |      including ``'\\t'`` (tab), ``'\\n'``, ``'\\r'`` and ``'\\0'``.\n",
      "     |  \n",
      "     |  decode(self, s, _w=<built-in method match of re.Pattern object at 0x0000027C157DDF30>)\n",
      "     |      Return the Python representation of ``s`` (a ``str`` instance\n",
      "     |      containing a JSON document).\n",
      "     |  \n",
      "     |  raw_decode(self, s, idx=0)\n",
      "     |      Decode a JSON document from ``s`` (a ``str`` beginning with\n",
      "     |      a JSON document) and return a 2-tuple of the Python\n",
      "     |      representation and the index in ``s`` where the document ended.\n",
      "     |      \n",
      "     |      This can be used to decode a JSON document from a string that may\n",
      "     |      have extraneous data at the end.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class JSONEncoder(builtins.object)\n",
      "     |  JSONEncoder(*, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, sort_keys=False, indent=None, separators=None, default=None)\n",
      "     |  \n",
      "     |  Extensible JSON <http://json.org> encoder for Python data structures.\n",
      "     |  \n",
      "     |  Supports the following objects and types by default:\n",
      "     |  \n",
      "     |  +-------------------+---------------+\n",
      "     |  | Python            | JSON          |\n",
      "     |  +===================+===============+\n",
      "     |  | dict              | object        |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | list, tuple       | array         |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | str               | string        |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | int, float        | number        |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | True              | true          |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | False             | false         |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | None              | null          |\n",
      "     |  +-------------------+---------------+\n",
      "     |  \n",
      "     |  To extend this to recognize other objects, subclass and implement a\n",
      "     |  ``.default()`` method with another method that returns a serializable\n",
      "     |  object for ``o`` if possible, otherwise it should call the superclass\n",
      "     |  implementation (to raise ``TypeError``).\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, sort_keys=False, indent=None, separators=None, default=None)\n",
      "     |      Constructor for JSONEncoder, with sensible defaults.\n",
      "     |      \n",
      "     |      If skipkeys is false, then it is a TypeError to attempt\n",
      "     |      encoding of keys that are not str, int, float or None.  If\n",
      "     |      skipkeys is True, such items are simply skipped.\n",
      "     |      \n",
      "     |      If ensure_ascii is true, the output is guaranteed to be str\n",
      "     |      objects with all incoming non-ASCII characters escaped.  If\n",
      "     |      ensure_ascii is false, the output can contain non-ASCII characters.\n",
      "     |      \n",
      "     |      If check_circular is true, then lists, dicts, and custom encoded\n",
      "     |      objects will be checked for circular references during encoding to\n",
      "     |      prevent an infinite recursion (which would cause an OverflowError).\n",
      "     |      Otherwise, no such check takes place.\n",
      "     |      \n",
      "     |      If allow_nan is true, then NaN, Infinity, and -Infinity will be\n",
      "     |      encoded as such.  This behavior is not JSON specification compliant,\n",
      "     |      but is consistent with most JavaScript based encoders and decoders.\n",
      "     |      Otherwise, it will be a ValueError to encode such floats.\n",
      "     |      \n",
      "     |      If sort_keys is true, then the output of dictionaries will be\n",
      "     |      sorted by key; this is useful for regression tests to ensure\n",
      "     |      that JSON serializations can be compared on a day-to-day basis.\n",
      "     |      \n",
      "     |      If indent is a non-negative integer, then JSON array\n",
      "     |      elements and object members will be pretty-printed with that\n",
      "     |      indent level.  An indent level of 0 will only insert newlines.\n",
      "     |      None is the most compact representation.\n",
      "     |      \n",
      "     |      If specified, separators should be an (item_separator, key_separator)\n",
      "     |      tuple.  The default is (', ', ': ') if *indent* is ``None`` and\n",
      "     |      (',', ': ') otherwise.  To get the most compact JSON representation,\n",
      "     |      you should specify (',', ':') to eliminate whitespace.\n",
      "     |      \n",
      "     |      If specified, default is a function that gets called for objects\n",
      "     |      that can't otherwise be serialized.  It should return a JSON encodable\n",
      "     |      version of the object or raise a ``TypeError``.\n",
      "     |  \n",
      "     |  default(self, o)\n",
      "     |      Implement this method in a subclass such that it returns\n",
      "     |      a serializable object for ``o``, or calls the base implementation\n",
      "     |      (to raise a ``TypeError``).\n",
      "     |      \n",
      "     |      For example, to support arbitrary iterators, you could\n",
      "     |      implement default like this::\n",
      "     |      \n",
      "     |          def default(self, o):\n",
      "     |              try:\n",
      "     |                  iterable = iter(o)\n",
      "     |              except TypeError:\n",
      "     |                  pass\n",
      "     |              else:\n",
      "     |                  return list(iterable)\n",
      "     |              # Let the base class default method raise the TypeError\n",
      "     |              return JSONEncoder.default(self, o)\n",
      "     |  \n",
      "     |  encode(self, o)\n",
      "     |      Return a JSON string representation of a Python data structure.\n",
      "     |      \n",
      "     |      >>> from json.encoder import JSONEncoder\n",
      "     |      >>> JSONEncoder().encode({\"foo\": [\"bar\", \"baz\"]})\n",
      "     |      '{\"foo\": [\"bar\", \"baz\"]}'\n",
      "     |  \n",
      "     |  iterencode(self, o, _one_shot=False)\n",
      "     |      Encode the given object and yield each string\n",
      "     |      representation as available.\n",
      "     |      \n",
      "     |      For example::\n",
      "     |      \n",
      "     |          for chunk in JSONEncoder().iterencode(bigobject):\n",
      "     |              mysocket.write(chunk)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  item_separator = ', '\n",
      "     |  \n",
      "     |  key_separator = ': '\n",
      "\n",
      "FUNCTIONS\n",
      "    dump(obj, fp, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)\n",
      "        Serialize ``obj`` as a JSON formatted stream to ``fp`` (a\n",
      "        ``.write()``-supporting file-like object).\n",
      "        \n",
      "        If ``skipkeys`` is true then ``dict`` keys that are not basic types\n",
      "        (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n",
      "        instead of raising a ``TypeError``.\n",
      "        \n",
      "        If ``ensure_ascii`` is false, then the strings written to ``fp`` can\n",
      "        contain non-ASCII characters if they appear in strings contained in\n",
      "        ``obj``. Otherwise, all such characters are escaped in JSON strings.\n",
      "        \n",
      "        If ``check_circular`` is false, then the circular reference check\n",
      "        for container types will be skipped and a circular reference will\n",
      "        result in an ``OverflowError`` (or worse).\n",
      "        \n",
      "        If ``allow_nan`` is false, then it will be a ``ValueError`` to\n",
      "        serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``)\n",
      "        in strict compliance of the JSON specification, instead of using the\n",
      "        JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n",
      "        \n",
      "        If ``indent`` is a non-negative integer, then JSON array elements and\n",
      "        object members will be pretty-printed with that indent level. An indent\n",
      "        level of 0 will only insert newlines. ``None`` is the most compact\n",
      "        representation.\n",
      "        \n",
      "        If specified, ``separators`` should be an ``(item_separator, key_separator)``\n",
      "        tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n",
      "        ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n",
      "        you should specify ``(',', ':')`` to eliminate whitespace.\n",
      "        \n",
      "        ``default(obj)`` is a function that should return a serializable version\n",
      "        of obj or raise TypeError. The default simply raises TypeError.\n",
      "        \n",
      "        If *sort_keys* is true (default: ``False``), then the output of\n",
      "        dictionaries will be sorted by key.\n",
      "        \n",
      "        To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n",
      "        ``.default()`` method to serialize additional types), specify it with\n",
      "        the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n",
      "    \n",
      "    dumps(obj, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)\n",
      "        Serialize ``obj`` to a JSON formatted ``str``.\n",
      "        \n",
      "        If ``skipkeys`` is true then ``dict`` keys that are not basic types\n",
      "        (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n",
      "        instead of raising a ``TypeError``.\n",
      "        \n",
      "        If ``ensure_ascii`` is false, then the return value can contain non-ASCII\n",
      "        characters if they appear in strings contained in ``obj``. Otherwise, all\n",
      "        such characters are escaped in JSON strings.\n",
      "        \n",
      "        If ``check_circular`` is false, then the circular reference check\n",
      "        for container types will be skipped and a circular reference will\n",
      "        result in an ``OverflowError`` (or worse).\n",
      "        \n",
      "        If ``allow_nan`` is false, then it will be a ``ValueError`` to\n",
      "        serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in\n",
      "        strict compliance of the JSON specification, instead of using the\n",
      "        JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n",
      "        \n",
      "        If ``indent`` is a non-negative integer, then JSON array elements and\n",
      "        object members will be pretty-printed with that indent level. An indent\n",
      "        level of 0 will only insert newlines. ``None`` is the most compact\n",
      "        representation.\n",
      "        \n",
      "        If specified, ``separators`` should be an ``(item_separator, key_separator)``\n",
      "        tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n",
      "        ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n",
      "        you should specify ``(',', ':')`` to eliminate whitespace.\n",
      "        \n",
      "        ``default(obj)`` is a function that should return a serializable version\n",
      "        of obj or raise TypeError. The default simply raises TypeError.\n",
      "        \n",
      "        If *sort_keys* is true (default: ``False``), then the output of\n",
      "        dictionaries will be sorted by key.\n",
      "        \n",
      "        To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n",
      "        ``.default()`` method to serialize additional types), specify it with\n",
      "        the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n",
      "    \n",
      "    load(fp, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)\n",
      "        Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\n",
      "        a JSON document) to a Python object.\n",
      "        \n",
      "        ``object_hook`` is an optional function that will be called with the\n",
      "        result of any object literal decode (a ``dict``). The return value of\n",
      "        ``object_hook`` will be used instead of the ``dict``. This feature\n",
      "        can be used to implement custom decoders (e.g. JSON-RPC class hinting).\n",
      "        \n",
      "        ``object_pairs_hook`` is an optional function that will be called with the\n",
      "        result of any object literal decoded with an ordered list of pairs.  The\n",
      "        return value of ``object_pairs_hook`` will be used instead of the ``dict``.\n",
      "        This feature can be used to implement custom decoders.  If ``object_hook``\n",
      "        is also defined, the ``object_pairs_hook`` takes priority.\n",
      "        \n",
      "        To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``\n",
      "        kwarg; otherwise ``JSONDecoder`` is used.\n",
      "    \n",
      "    loads(s, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)\n",
      "        Deserialize ``s`` (a ``str``, ``bytes`` or ``bytearray`` instance\n",
      "        containing a JSON document) to a Python object.\n",
      "        \n",
      "        ``object_hook`` is an optional function that will be called with the\n",
      "        result of any object literal decode (a ``dict``). The return value of\n",
      "        ``object_hook`` will be used instead of the ``dict``. This feature\n",
      "        can be used to implement custom decoders (e.g. JSON-RPC class hinting).\n",
      "        \n",
      "        ``object_pairs_hook`` is an optional function that will be called with the\n",
      "        result of any object literal decoded with an ordered list of pairs.  The\n",
      "        return value of ``object_pairs_hook`` will be used instead of the ``dict``.\n",
      "        This feature can be used to implement custom decoders.  If ``object_hook``\n",
      "        is also defined, the ``object_pairs_hook`` takes priority.\n",
      "        \n",
      "        ``parse_float``, if specified, will be called with the string\n",
      "        of every JSON float to be decoded. By default this is equivalent to\n",
      "        float(num_str). This can be used to use another datatype or parser\n",
      "        for JSON floats (e.g. decimal.Decimal).\n",
      "        \n",
      "        ``parse_int``, if specified, will be called with the string\n",
      "        of every JSON int to be decoded. By default this is equivalent to\n",
      "        int(num_str). This can be used to use another datatype or parser\n",
      "        for JSON integers (e.g. float).\n",
      "        \n",
      "        ``parse_constant``, if specified, will be called with one of the\n",
      "        following strings: -Infinity, Infinity, NaN.\n",
      "        This can be used to raise an exception if invalid JSON numbers\n",
      "        are encountered.\n",
      "        \n",
      "        To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``\n",
      "        kwarg; otherwise ``JSONDecoder`` is used.\n",
      "        \n",
      "        The ``encoding`` argument is ignored and deprecated since Python 3.1.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['dump', 'dumps', 'load', 'loads', 'JSONDecoder', 'JSONDecod...\n",
      "\n",
      "VERSION\n",
      "    2.0.9\n",
      "\n",
      "AUTHOR\n",
      "    Bob Ippolito <bob@redivi.com>\n",
      "\n",
      "FILE\n",
      "    c:\\program files\\python38\\lib\\json\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
